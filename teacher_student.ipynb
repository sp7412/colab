{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "teacher_student.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sp7412/colab/blob/master/teacher_student.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fgu0r3gHk_s7",
        "colab_type": "text"
      },
      "source": [
        "In this notebook I use knowledge distillation on MNIST.\n",
        "The goal is not to classify MNIST as well as possible, but rather show improvement thanks to distillation on a nano model.\n",
        "\n",
        "Bigger model achivies just barely 99%.\n",
        "\n",
        "Smaller model seems to improve around 0.3% depending on the run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tW6Y2I1czBxK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgp6OAjxzHh4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9119552f-10f0-4f52-9b28-3d2c37456d68"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgWaFG4kzLEk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train,  test = mnist\n",
        "x_train, y_train = train\n",
        "x_test, y_test = train\n",
        "\n",
        "x_train, x_test = x_train/255, x_test/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IJre5MG0R2M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a0cc95ee-0560-4e85-c016-288a66e4c7e8"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAZW3-J_AUsq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax_sparse_categorical_crossentropy(labels, logits):\n",
        "  softmaxed = tf.keras.backend.softmax(logits)\n",
        "\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, softmaxed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEed69to3FbE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "71a10c2f-99b8-440e-d2b4-425d5a3b22d0"
      },
      "source": [
        "control_model = tf.keras.models.Sequential([\n",
        "  tf.keras.Input([28, 28]), \n",
        "  tf.keras.layers.Reshape([28, 28, 1]), \n",
        "  tf.keras.layers.Conv2D(64, 3, 2, activation='relu'), \n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Conv2D(64, 3, 2, activation='relu'), \n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.GlobalAveragePooling2D(), \n",
        "  #tf.keras.layers.Dense(10, activation='softmax')])\n",
        "  tf.keras.layers.Dense(10, activation=None)])\n",
        "\n",
        "#control_model.compile('adam', 'sparse_categorical_crossentropy', ['accuracy'])\n",
        "control_model.compile('adam', softmax_sparse_categorical_crossentropy, ['accuracy'])\n",
        "control_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_33\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_33 (Reshape)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_67 (Conv2D)           (None, 13, 13, 64)        640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 13, 13, 64)        256       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_68 (Conv2D)           (None, 6, 6, 64)          36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 6, 6, 64)          256       \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_33  (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 38,730\n",
            "Trainable params: 38,474\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgAqswuo1usC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dfb8fa5d-62ba-46e9-ebfd-99f645841e05"
      },
      "source": [
        "control_model.fit(x_train, y_train, epochs=30, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.7650 - accuracy: 0.7840 - val_loss: 0.3173 - val_accuracy: 0.9091\n",
            "Epoch 2/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3200 - accuracy: 0.9090 - val_loss: 0.2435 - val_accuracy: 0.9283\n",
            "Epoch 3/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2556 - accuracy: 0.9242 - val_loss: 0.1639 - val_accuracy: 0.9518\n",
            "Epoch 4/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2215 - accuracy: 0.9323 - val_loss: 0.1691 - val_accuracy: 0.9504\n",
            "Epoch 5/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2074 - accuracy: 0.9372 - val_loss: 0.1511 - val_accuracy: 0.9544\n",
            "Epoch 6/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1895 - accuracy: 0.9413 - val_loss: 0.1216 - val_accuracy: 0.9631\n",
            "Epoch 7/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1841 - accuracy: 0.9422 - val_loss: 0.1270 - val_accuracy: 0.9625\n",
            "Epoch 8/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1716 - accuracy: 0.9462 - val_loss: 0.1138 - val_accuracy: 0.9651\n",
            "Epoch 9/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1686 - accuracy: 0.9468 - val_loss: 0.1358 - val_accuracy: 0.9572\n",
            "Epoch 10/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1647 - accuracy: 0.9484 - val_loss: 0.1110 - val_accuracy: 0.9658\n",
            "Epoch 11/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1591 - accuracy: 0.9500 - val_loss: 0.1201 - val_accuracy: 0.9627\n",
            "Epoch 12/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1537 - accuracy: 0.9516 - val_loss: 0.0977 - val_accuracy: 0.9710\n",
            "Epoch 13/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1513 - accuracy: 0.9526 - val_loss: 0.1269 - val_accuracy: 0.9609\n",
            "Epoch 14/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1508 - accuracy: 0.9528 - val_loss: 0.1408 - val_accuracy: 0.9582\n",
            "Epoch 15/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1479 - accuracy: 0.9532 - val_loss: 0.1040 - val_accuracy: 0.9674\n",
            "Epoch 16/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1432 - accuracy: 0.9554 - val_loss: 0.0965 - val_accuracy: 0.9700\n",
            "Epoch 17/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1378 - accuracy: 0.9564 - val_loss: 0.0920 - val_accuracy: 0.9707\n",
            "Epoch 18/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1397 - accuracy: 0.9553 - val_loss: 0.0936 - val_accuracy: 0.9710\n",
            "Epoch 19/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1339 - accuracy: 0.9565 - val_loss: 0.0945 - val_accuracy: 0.9694\n",
            "Epoch 20/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1347 - accuracy: 0.9575 - val_loss: 0.1125 - val_accuracy: 0.9638\n",
            "Epoch 21/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1314 - accuracy: 0.9583 - val_loss: 0.0945 - val_accuracy: 0.9714\n",
            "Epoch 22/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1319 - accuracy: 0.9574 - val_loss: 0.0919 - val_accuracy: 0.9697\n",
            "Epoch 23/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1296 - accuracy: 0.9589 - val_loss: 0.0922 - val_accuracy: 0.9707\n",
            "Epoch 24/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1257 - accuracy: 0.9580 - val_loss: 0.0936 - val_accuracy: 0.9697\n",
            "Epoch 25/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1258 - accuracy: 0.9595 - val_loss: 0.0868 - val_accuracy: 0.9722\n",
            "Epoch 26/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1226 - accuracy: 0.9612 - val_loss: 0.0904 - val_accuracy: 0.9700\n",
            "Epoch 27/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1224 - accuracy: 0.9614 - val_loss: 0.0876 - val_accuracy: 0.9711\n",
            "Epoch 28/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1259 - accuracy: 0.9600 - val_loss: 0.0897 - val_accuracy: 0.9731\n",
            "Epoch 29/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1212 - accuracy: 0.9600 - val_loss: 0.0838 - val_accuracy: 0.9738\n",
            "Epoch 30/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1193 - accuracy: 0.9613 - val_loss: 0.0956 - val_accuracy: 0.9705\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa4d3354438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loTRdEt31ynb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "a582a668-133a-45f9-fdd4-1a9a1e947b55"
      },
      "source": [
        "teacher_model = tf.keras.models.Sequential([\n",
        "  tf.keras.Input([28, 28]), \n",
        "  tf.keras.layers.Reshape([28, 28, 1]), \n",
        "  tf.keras.layers.Conv2D(64, 3, 2, activation='relu'), \n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Conv2D(64, 3, 2, activation='relu'), \n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Conv2D(64, 3, 2, activation='relu'), \n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.GlobalAveragePooling2D(), \n",
        "  #tf.keras.layers.Dense(10, activation='softmax')])\n",
        "  tf.keras.layers.Dense(10, activation=None)])\n",
        "\n",
        "#teacher_model.compile('adam', 'sparse_categorical_crossentropy', ['accuracy'])\n",
        "teacher_model.compile('adam', softmax_sparse_categorical_crossentropy, ['accuracy'])\n",
        "teacher_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_16 (Reshape)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 13, 13, 64)        640       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 13, 13, 64)        256       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 6, 6, 64)          36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 6, 6, 64)          256       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 2, 2, 64)          36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 2, 2, 64)          256       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2, 2, 64)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_16  (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 75,914\n",
            "Trainable params: 75,530\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD58hAMl4Tae",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2203b5b2-fb4a-4f1c-e795-5441c877c756"
      },
      "source": [
        "teacher_model.fit(x_train, y_train, epochs=30, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3257 - accuracy: 0.9080 - val_loss: 0.0899 - val_accuracy: 0.9736\n",
            "Epoch 2/30\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1265 - accuracy: 0.9624 - val_loss: 0.0720 - val_accuracy: 0.9773\n",
            "Epoch 3/30\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0955 - accuracy: 0.9707 - val_loss: 0.0591 - val_accuracy: 0.9831\n",
            "Epoch 4/30\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0817 - accuracy: 0.9755 - val_loss: 0.0512 - val_accuracy: 0.9837\n",
            "Epoch 5/30\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0702 - accuracy: 0.9781 - val_loss: 0.0475 - val_accuracy: 0.9866\n",
            "Epoch 6/30\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0681 - accuracy: 0.9788 - val_loss: 0.0424 - val_accuracy: 0.9870\n",
            "Epoch 7/30\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0608 - accuracy: 0.9809 - val_loss: 0.0436 - val_accuracy: 0.9879\n",
            "Epoch 8/30\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0562 - accuracy: 0.9825 - val_loss: 0.0408 - val_accuracy: 0.9885\n",
            "Epoch 9/30\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0526 - accuracy: 0.9833 - val_loss: 0.0437 - val_accuracy: 0.9870\n",
            "Epoch 10/30\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0493 - accuracy: 0.9835 - val_loss: 0.0431 - val_accuracy: 0.9873\n",
            "Epoch 11/30\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0482 - accuracy: 0.9846 - val_loss: 0.0430 - val_accuracy: 0.9881\n",
            "Epoch 12/30\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0448 - accuracy: 0.9855 - val_loss: 0.0388 - val_accuracy: 0.9896\n",
            "Epoch 13/30\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0416 - accuracy: 0.9866 - val_loss: 0.0376 - val_accuracy: 0.9892\n",
            "Epoch 14/30\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0420 - accuracy: 0.9863 - val_loss: 0.0391 - val_accuracy: 0.9896\n",
            "Epoch 15/30\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0395 - accuracy: 0.9872 - val_loss: 0.0377 - val_accuracy: 0.9892\n",
            "Epoch 16/30\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0379 - accuracy: 0.9871 - val_loss: 0.0400 - val_accuracy: 0.9886\n",
            "Epoch 17/30\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0381 - accuracy: 0.9877 - val_loss: 0.0366 - val_accuracy: 0.9894\n",
            "Epoch 18/30\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0342 - accuracy: 0.9887 - val_loss: 0.0396 - val_accuracy: 0.9884\n",
            "Epoch 19/30\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0362 - accuracy: 0.9883 - val_loss: 0.0398 - val_accuracy: 0.9886\n",
            "Epoch 20/30\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0337 - accuracy: 0.9886 - val_loss: 0.0393 - val_accuracy: 0.9883\n",
            "Epoch 21/30\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0300 - accuracy: 0.9898 - val_loss: 0.0376 - val_accuracy: 0.9898\n",
            "Epoch 22/30\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0317 - accuracy: 0.9894 - val_loss: 0.0348 - val_accuracy: 0.9901\n",
            "Epoch 23/30\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0334 - accuracy: 0.9889 - val_loss: 0.0382 - val_accuracy: 0.9899\n",
            "Epoch 24/30\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0300 - accuracy: 0.9902 - val_loss: 0.0363 - val_accuracy: 0.9897\n",
            "Epoch 25/30\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0288 - accuracy: 0.9902 - val_loss: 0.0363 - val_accuracy: 0.9902\n",
            "Epoch 26/30\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0293 - accuracy: 0.9904 - val_loss: 0.0375 - val_accuracy: 0.9903\n",
            "Epoch 27/30\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0281 - accuracy: 0.9906 - val_loss: 0.0377 - val_accuracy: 0.9895\n",
            "Epoch 28/30\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0273 - accuracy: 0.9906 - val_loss: 0.0361 - val_accuracy: 0.9896\n",
            "Epoch 29/30\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0255 - accuracy: 0.9911 - val_loss: 0.0371 - val_accuracy: 0.9900\n",
            "Epoch 30/30\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0298 - accuracy: 0.9899 - val_loss: 0.0356 - val_accuracy: 0.9903\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa702167b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEYdm_B0HV8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "soft_labels = teacher_model.predict(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFrdoBwVGV8i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temperature = 3\n",
        "afterwards_temperature = 1\n",
        "\n",
        "def temperature_softmax(logits):\n",
        "  soft_logits = tf.keras.backend.exp(logits / temperature)\n",
        "  return soft_logits / tf.keras.backend.sum(soft_logits, axis=-1, keepdims=True) / afterwards_temperature\n",
        "\n",
        "def distillation_loss(labels, logits):\n",
        "  labels = temperature_softmax(labels)\n",
        "  logits = temperature_softmax(logits)\n",
        "\n",
        "  return -tf.keras.backend.mean(labels * tf.keras.backend.log(logits))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCHSkRW554Jq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "1b4b9ed3-d1d9-4866-d21b-33ad4fae566b"
      },
      "source": [
        "student_model = tf.keras.models.Sequential([\n",
        "  tf.keras.Input([28, 28]), \n",
        "  tf.keras.layers.Reshape([28, 28, 1]), \n",
        "  tf.keras.layers.Conv2D(64, 3, 2, activation='relu'), \n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Conv2D(64, 3, 2, activation='relu'), \n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.GlobalAveragePooling2D(), \n",
        "  #tf.keras.layers.Dense(10, activation='softmax')])\n",
        "  tf.keras.layers.Dense(10, activation=None)])\n",
        "\n",
        "student_model.compile('adam', distillation_loss, ['accuracy'])\n",
        "student_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_40\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_40 (Reshape)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_81 (Conv2D)           (None, 13, 13, 64)        640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 13, 13, 64)        256       \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_82 (Conv2D)           (None, 6, 6, 64)          36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 6, 6, 64)          256       \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_40  (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 38,730\n",
            "Trainable params: 38,474\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEO9BBp-F4ix",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0d7d1c13-4a82-4afd-94db-8cced299ba63"
      },
      "source": [
        "student_model.fit(x_train, soft_labels, epochs=30, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0426 - accuracy: 0.9638 - val_loss: 0.0387 - val_accuracy: 0.9765\n",
            "Epoch 2/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0427 - accuracy: 0.9624 - val_loss: 0.0387 - val_accuracy: 0.9758\n",
            "Epoch 3/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0424 - accuracy: 0.9636 - val_loss: 0.0392 - val_accuracy: 0.9730\n",
            "Epoch 4/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0426 - accuracy: 0.9625 - val_loss: 0.0388 - val_accuracy: 0.9750\n",
            "Epoch 5/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0426 - accuracy: 0.9637 - val_loss: 0.0387 - val_accuracy: 0.9758\n",
            "Epoch 6/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0425 - accuracy: 0.9637 - val_loss: 0.0392 - val_accuracy: 0.9745\n",
            "Epoch 7/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0424 - accuracy: 0.9638 - val_loss: 0.0388 - val_accuracy: 0.9758\n",
            "Epoch 8/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0422 - accuracy: 0.9642 - val_loss: 0.0388 - val_accuracy: 0.9768\n",
            "Epoch 9/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0422 - accuracy: 0.9640 - val_loss: 0.0388 - val_accuracy: 0.9743\n",
            "Epoch 10/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0422 - accuracy: 0.9641 - val_loss: 0.0394 - val_accuracy: 0.9728\n",
            "Epoch 11/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0423 - accuracy: 0.9638 - val_loss: 0.0394 - val_accuracy: 0.9716\n",
            "Epoch 12/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0422 - accuracy: 0.9642 - val_loss: 0.0394 - val_accuracy: 0.9749\n",
            "Epoch 13/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0422 - accuracy: 0.9644 - val_loss: 0.0387 - val_accuracy: 0.9765\n",
            "Epoch 14/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0422 - accuracy: 0.9652 - val_loss: 0.0397 - val_accuracy: 0.9758\n",
            "Epoch 15/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0421 - accuracy: 0.9650 - val_loss: 0.0388 - val_accuracy: 0.9758\n",
            "Epoch 16/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0421 - accuracy: 0.9643 - val_loss: 0.0388 - val_accuracy: 0.9765\n",
            "Epoch 17/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0420 - accuracy: 0.9663 - val_loss: 0.0391 - val_accuracy: 0.9758\n",
            "Epoch 18/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0421 - accuracy: 0.9661 - val_loss: 0.0384 - val_accuracy: 0.9769\n",
            "Epoch 19/30\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0420 - accuracy: 0.9649 - val_loss: 0.0393 - val_accuracy: 0.9726\n",
            "Epoch 20/30\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0419 - accuracy: 0.9659 - val_loss: 0.0385 - val_accuracy: 0.9768\n",
            "Epoch 21/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0419 - accuracy: 0.9667 - val_loss: 0.0387 - val_accuracy: 0.9765\n",
            "Epoch 22/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0418 - accuracy: 0.9672 - val_loss: 0.0389 - val_accuracy: 0.9755\n",
            "Epoch 23/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0418 - accuracy: 0.9670 - val_loss: 0.0389 - val_accuracy: 0.9737\n",
            "Epoch 24/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0419 - accuracy: 0.9665 - val_loss: 0.0388 - val_accuracy: 0.9772\n",
            "Epoch 25/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0418 - accuracy: 0.9662 - val_loss: 0.0386 - val_accuracy: 0.9757\n",
            "Epoch 26/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0418 - accuracy: 0.9665 - val_loss: 0.0386 - val_accuracy: 0.9764\n",
            "Epoch 27/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0417 - accuracy: 0.9671 - val_loss: 0.0403 - val_accuracy: 0.9721\n",
            "Epoch 28/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0416 - accuracy: 0.9685 - val_loss: 0.0387 - val_accuracy: 0.9743\n",
            "Epoch 29/30\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0417 - accuracy: 0.9673 - val_loss: 0.0388 - val_accuracy: 0.9762\n",
            "Epoch 30/30\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0418 - accuracy: 0.9665 - val_loss: 0.0383 - val_accuracy: 0.9766\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa4ca310278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvuq5v3hHc3V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}